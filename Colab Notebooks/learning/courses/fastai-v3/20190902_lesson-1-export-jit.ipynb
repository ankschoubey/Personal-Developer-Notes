{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"Copy of lesson-1-export-jit.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/fastai/course-v3/blob/master/docs/production/lesson-1-export-jit.ipynb","timestamp":1567408166735}],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"l_OyRIfDzn5h","colab_type":"text"},"source":["# fast.ai lesson 1 - training on Notebook Instance and export to torch.jit model"]},{"cell_type":"markdown","metadata":{"id":"gEB6UwMUzn5j","colab_type":"text"},"source":["## Overview\n","This notebook shows how to use the SageMaker Python SDK to train your fast.ai model on a SageMaker notebook instance then export it as a torch.jit model to be used for inference on AWS Lambda.\n","\n","## Set up the environment\n","\n","You will need a Jupyter notebook with the `boto3` and `fastai` libraries installed. You can do this with the command `pip install boto3 fastai`\n","\n","This notebook was created and tested on a single ml.p3.2xlarge notebook instance. \n"]},{"cell_type":"markdown","metadata":{"id":"yn5qdZSDzn5k","colab_type":"text"},"source":["## Train your model\n","\n","We are going to train a fast.ai model as per [Lesson 1 of the fast.ai MOOC course](https://course.fast.ai/videos/?lesson=1) locally on the SageMaker Notebook instance. We will then save the model weights and upload them to S3.\n","\n"]},{"cell_type":"code","metadata":{"id":"p7U7JCKOzn5l","colab_type":"code","colab":{}},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lv0HIXyEzn5o","colab_type":"code","colab":{}},"source":["import os\n","import io\n","import tarfile\n","\n","import PIL\n","\n","import boto3\n","\n","from fastai.vision import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1A2loAZfzn5q","colab_type":"code","colab":{}},"source":["path = untar_data(URLs.PETS); path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"teBUtA0ezn5s","colab_type":"code","colab":{}},"source":["path_anno = path/'annotations'\n","path_img = path/'images'\n","fnames = get_image_files(path_img)\n","np.random.seed(2)\n","pat = re.compile(r'/([^/]+)_\\d+.jpg$')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qILO4dFBzn5u","colab_type":"code","colab":{}},"source":["bs=64\n","img_size=299"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Drz7p8s2zn5w","colab_type":"code","colab":{}},"source":["data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(),\n","                                   size=img_size, bs=bs//2).normalize(imagenet_stats)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dImC8CjVzn5z","colab_type":"code","colab":{}},"source":["learn = cnn_learner(data, models.resnet50, metrics=error_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wc-9bL9uzn51","colab_type":"code","colab":{}},"source":["learn.lr_find()\n","learn.recorder.plot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0A1ZaIYIzn54","colab_type":"code","colab":{}},"source":["learn.fit_one_cycle(8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjxW5vh0zn56","colab_type":"code","colab":{}},"source":["learn.unfreeze()\n","learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7vG0LDvhzn58","colab_type":"text"},"source":["## Export model and upload to S3"]},{"cell_type":"markdown","metadata":{"id":"Cchr9OWYzn59","colab_type":"text"},"source":["Now that we have trained our model we need to export it, create a tarball of the artefacts and upload to S3.\n"]},{"cell_type":"markdown","metadata":{"id":"LPt9hrmmzn5-","colab_type":"text"},"source":["First we need to export the class names from the data object into a text file."]},{"cell_type":"code","metadata":{"id":"oyAEhRVdzn5-","colab_type":"code","colab":{}},"source":["save_texts(path_img/'models/classes.txt', data.classes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HMdCmXxfzn6B","colab_type":"text"},"source":["Now we need to export the model in the [PyTorch TorchScript format](https://pytorch.org/docs/stable/jit.html) so we can load into an AWS Lambda function."]},{"cell_type":"code","metadata":{"id":"vn8mcEAMzn6C","colab_type":"code","colab":{}},"source":["trace_input = torch.ones(1,3,img_size,img_size).cuda()\n","jit_model = torch.jit.trace(learn.model.float(), trace_input)\n","model_file='resnet50_jit.pth'\n","output_path = str(path_img/f'models/{model_file}')\n","torch.jit.save(jit_model, output_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s0w7bffWzn6E","colab_type":"text"},"source":["Next step is to create a tarfile of the exported classes file and model weights."]},{"cell_type":"code","metadata":{"id":"_dZ6ZXPczn6F","colab_type":"code","colab":{}},"source":["tar_file=path_img/'models/model.tar.gz'\n","classes_file='classes.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1R3UpTrMzn6H","colab_type":"code","colab":{}},"source":["with tarfile.open(tar_file, 'w:gz') as f:\n","    f.add(path_img/f'models/{model_file}', arcname=model_file)\n","    f.add(path_img/f'models/{classes_file}', arcname=classes_file)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6Sg4vWTzn6J","colab_type":"text"},"source":["Now we need to upload the model tarball to S3."]},{"cell_type":"code","metadata":{"id":"fhyDW1PIzn6J","colab_type":"code","colab":{}},"source":["s3 = boto3.resource('s3')\n","s3.meta.client.upload_file(str(tar_file), 'REPLACE_WITH_YOUR_BUCKET_NAME', 'fastai-models/lesson1/model.tar.gz')"],"execution_count":0,"outputs":[]}]}